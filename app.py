# app.py
from __future__ import annotations

import os
import hashlib
import time
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, List, Optional

import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from llm_quality import judge_quality_one, QualityJudgement

from arxiv_client import fetch_arxiv_latest

# âœ… Match only
from llm_match import match_one, MatchResult

from storage import (
    ensure_dirs,
    load_csv,
    upsert_rows,
    now_iso,
    download_pdf,
    safe_filename,
)

load_dotenv()

DEFAULT_LIBRARY_DIR = "library"
DEFAULT_CSV_PATH = os.path.join(DEFAULT_LIBRARY_DIR, "papers.csv")


# ----------------------------
# Utilities
# ----------------------------
def batch_quality_llm(
    rows: List[Dict[str, Any]],
    model: str,
    sleep_s: float = 0.0,
    max_retry: int = 2,
) -> List[QualityJudgement]:
    judgements: List[QualityJudgement] = []
    n = len(rows)
    progress = st.progress(0)

    for i, r in enumerate(rows):
        uid = str(r.get("uid", ""))
        title = str(r.get("title", ""))
        abstract = str(r.get("abstract", ""))
        authors = str(r.get("authors", "") or "")
        authors_list = [a.strip() for a in authors.split(";") if a.strip()]
        primary_category = str(r.get("primary_category", "") or "") or None

        last_err = None
        for _ in range(max_retry + 1):
            try:
                j = judge_quality_one(
                    uid=uid,
                    title=title,
                    abstract=abstract,
                    authors=authors_list,
                    primary_category=primary_category,
                    model=model,
                )
                judgements.append(j)
                last_err = None
                break
            except Exception as e:
                last_err = e
                time.sleep(0.8)

        if last_err is not None:
            judgements.append(QualityJudgement(
                uid=uid,
                quality_score=0.0,
                status="rejected",
                quality_reason=f"ERROR: {str(last_err)}",
            ))

        if sleep_s > 0:
            time.sleep(float(sleep_s))

        progress.progress(int((i + 1) / max(1, n) * 100))

    return judgements


def parse_dt_safe(x: Any) -> Optional[datetime]:
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return None
    s = str(x).strip()
    if not s:
        return None
    try:
        dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return dt
    except Exception:
        return None


def is_today(dt: Optional[datetime], tz=timezone.utc) -> bool:
    if dt is None:
        return False
    return dt.astimezone(tz).date() == datetime.now(tz).date()


def within_last_days(dt: Optional[datetime], days: int) -> bool:
    if dt is None:
        return False
    return dt >= datetime.now(timezone.utc) - timedelta(days=days)


def compute_prompt_hash(prompt: str) -> str:
    # âœ… keep consistent with llm_match._hash_prompt (sha256[:16])
    return hashlib.sha256(prompt.encode("utf-8")).hexdigest()[:16]


def make_local_uid(file_bytes: bytes, filename: str) -> str:
    h = hashlib.sha1()
    h.update(file_bytes)
    h.update(filename.encode("utf-8", errors="ignore"))
    return "local:" + h.hexdigest()[:16]


def infer_source(row: pd.Series) -> str:
    uid = str(row.get("uid", "") or "")
    if uid.startswith("local:"):
        return "local"
    arxiv_url = str(row.get("arxiv_url", "") or "")
    pdf_url = str(row.get("pdf_url", "") or "")
    if "arxiv.org" in arxiv_url or "arxiv.org" in pdf_url:
        return "arxiv"
    return "unknown"


def paper_to_row_arxiv(p: Any) -> Dict[str, Any]:
    # ä½  storage.py çš„ schema
    return {
        "uid": p.uid,
        "title": p.title,
        "abstract": p.abstract,
        "authors": "; ".join(p.authors),
        "published_at": p.published_at.isoformat(),
        "primary_category": p.primary_category or "",
        "categories": "; ".join(p.categories or []),
        "arxiv_url": p.arxiv_url,
        "pdf_url": p.pdf_url,
        "pdf_path": None,

        # Stage 1: Qualityï¼ˆç”± run_ingest_quality.py è´Ÿè´£ï¼‰
        "status": "pending",
        "quality_score": None,
        "quality_reason": None,
        "quality_reviewed_at": None,

        # Stage 2: Matchï¼ˆç”±æœ¬ app è´Ÿè´£ï¼‰
        "match_score": None,
        "match_reason": None,
        "match_summary": None,
        "match_prompt_hash": None,

        # Meta
        "added_at": now_iso(),
    }


def local_row_from_upload(uid: str, title: str, pdf_path: str, note: str = "") -> Dict[str, Any]:
    return {
        "uid": uid,
        "title": title,
        # æœ¬åœ° PDF çš„ abstract æš‚å­˜å¤‡æ³¨ï¼Œæ–¹ä¾¿ match å‘½ä¸­
        "abstract": note.strip(),
        "authors": "",
        "published_at": "",
        "primary_category": "",
        "categories": "",
        "arxiv_url": "",
        "pdf_url": "",
        "pdf_path": pdf_path,

        "status": "pending",
        "quality_score": None,
        "quality_reason": None,
        "quality_reviewed_at": None,

        "match_score": None,
        "match_reason": None,
        "match_summary": None,
        "match_prompt_hash": None,

        "added_at": now_iso(),
    }


def sort_for_browse(df: pd.DataFrame, score_col: str, mode: str) -> pd.DataFrame:
    df2 = df.copy()
    df2["_score"] = pd.to_numeric(df2.get(score_col), errors="coerce")
    df2["_published_dt"] = df2["published_at"].apply(parse_dt_safe)
    df2["_added_dt"] = df2["added_at"].apply(parse_dt_safe)

    if mode == "é«˜åˆ†ä¼˜å…ˆ":
        df2 = df2.sort_values(["_score", "_published_dt"], ascending=[False, False], na_position="last")
    elif mode == "æœ€æ–°å‘å¸ƒä¼˜å…ˆ":
        df2 = df2.sort_values(["_published_dt", "_score"], ascending=[False, False], na_position="last")
    else:
        df2 = df2.sort_values(["_added_dt", "_score"], ascending=[False, False], na_position="last")

    return df2.drop(columns=["_score"], errors="ignore")


# âœ… batch match using match_one (per-paper)
def batch_match_llm(
    prompt: str,
    rows: List[Dict[str, Any]],
    model: str,
    sleep_s: float = 0.0,
    max_retry: int = 2,
) -> List[MatchResult]:
    results: List[MatchResult] = []
    n = len(rows)
    progress = st.progress(0)

    for i, r in enumerate(rows):
        uid = str(r.get("uid", ""))
        title = str(r.get("title", ""))
        abstract = str(r.get("abstract", ""))
        authors = str(r.get("authors", ""))

        last_err = None
        for _ in range(max_retry + 1):
            try:
                res = match_one(
                    prompt=prompt,
                    uid=uid,
                    title=title,
                    abstract=abstract,
                    authors=authors,
                    model=model,
                )
                results.append(res)
                last_err = None
                break
            except Exception as e:
                last_err = e
                time.sleep(0.8)

        if last_err is not None:
            results.append(MatchResult(
                uid=uid,
                match_score=0.0,
                match_reason=f"ERROR: {str(last_err)}",
                match_summary="",
                prompt_hash=compute_prompt_hash(prompt),
            ))

        if sleep_s > 0:
            time.sleep(float(sleep_s))

        progress.progress(int((i + 1) / max(1, n) * 100))

    return results


# ----------------------------
# Streamlit UI
# ----------------------------
st.set_page_config(page_title="Paper Recommender (Browse + Match)", layout="wide")
st.title("ğŸ“š Paper Recommenderï¼ˆBrowse / Upload / arXiv / LLM Matchï¼‰")
st.caption("Quality è¯·ç”¨ run_ingest_quality.py è·‘ï¼›æœ¬ app ä¸åš Qualityï¼Œåªå±•ç¤ºç»“æœå¹¶æä¾› Matchã€‚")

st.sidebar.header("é…ç½®")
library_dir = st.sidebar.text_input("æœ¬åœ°è®ºæ–‡åº“ç›®å½•", value=DEFAULT_LIBRARY_DIR)
csv_path = st.sidebar.text_input("CSV è·¯å¾„", value=DEFAULT_CSV_PATH)
dirs = ensure_dirs(library_dir)
pdf_dir = dirs["pdf_dir"]

st.sidebar.markdown("---")
st.sidebar.subheader("LLM è®¾ç½®")
use_llm = st.sidebar.checkbox("å¯ç”¨ GPTï¼ˆä»…ç”¨äº Matchï¼‰", value=True)
model = st.sidebar.text_input("æ¨¡å‹å", value="gpt-5.2")

st.sidebar.markdown("---")
st.sidebar.subheader("PDF ä¸‹è½½è®¾ç½®ï¼ˆMatch åå¯é€‰ï¼‰")
download_top_k = st.sidebar.slider("ä¸‹è½½ Top Kï¼ˆæŒ‰ match_scoreï¼‰", 0, 50, 10)
force_redownload = st.sidebar.checkbox("å¼ºåˆ¶é‡æ–°ä¸‹è½½", value=False)

df_lib = load_csv(csv_path)
if len(df_lib) > 0:
    df_lib["source"] = df_lib.apply(infer_source, axis=1)
else:
    df_lib["source"] = None

tab_browse, tab_upload, tab_arxiv, tab_match = st.tabs([
    "ğŸ‘€ æµè§ˆï¼ˆQuality/Matchç»“æœï¼‰",
    "â¬†ï¸ æ‰¹é‡ä¸Šä¼  PDF",
    "ğŸ›°ï¸ æŠ“å– arXiv",
    "ğŸ¯ LLM Matchï¼ˆæŒ‰ Prompt åŒ¹é…ï¼‰",
])


# ----------------------------
# Browse
# ----------------------------
with tab_browse:
    st.subheader("ğŸ‘€ æµè§ˆè®ºæ–‡åº“ï¼ˆå« Quality ä¸ Match å­—æ®µï¼‰")

    if len(df_lib) == 0:
        st.info("ä½ çš„åº“è¿˜æ˜¯ç©ºçš„ï¼šå…ˆå»æŠ“ arXiv æˆ–ä¸Šä¼  PDFã€‚")
    else:
        colA, colB, colC, colD, colE, colF = st.columns([1, 1, 1, 1, 1, 1])

        with colA:
            view = st.selectbox("æµè§ˆè§†è§’", ["Qualityï¼ˆquality_scoreï¼‰", "Matchï¼ˆmatch_scoreï¼‰"], index=0)
        with colB:
            sort_mode = st.selectbox("æ’åº", ["é«˜åˆ†ä¼˜å…ˆ", "æœ€æ–°å‘å¸ƒä¼˜å…ˆ", "æœ€è¿‘æ·»åŠ ä¼˜å…ˆ"], index=0)
        with colC:
            status_filter = st.selectbox("çŠ¶æ€", ["å…¨éƒ¨", "pending", "accepted", "rejected"], index=0)
        with colD:
            source_filter = st.selectbox("æ¥æº", ["å…¨éƒ¨", "arxiv", "local"], index=0)
        with colE:
            min_score = st.slider("æœ€ä½åˆ†è¿‡æ»¤", 70, 100, 80)
        with colF:
            only_today = st.checkbox("åªçœ‹ä»Šå¤©æ–°å‘å¸ƒ", value=False)

        keyword = st.text_input("å…³é”®è¯è¿‡æ»¤ï¼ˆtitle/abstract/quality_reason/match_summaryï¼‰", value="")

        score_col = "quality_score" if view.startswith("Quality") else "match_score"

        df_show = df_lib.copy()
        df_show["_published_dt"] = df_show["published_at"].apply(parse_dt_safe)

        if status_filter != "å…¨éƒ¨":
            df_show = df_show[df_show["status"].fillna("").astype(str) == status_filter]

        if source_filter != "å…¨éƒ¨":
            df_show = df_show[df_show["source"].fillna("").astype(str) == source_filter]

        if only_today:
            df_show = df_show[df_show["_published_dt"].apply(lambda x: is_today(x, timezone.utc))]

        df_show["_score_num"] = pd.to_numeric(df_show.get(score_col), errors="coerce")
        df_scored = df_show[df_show["_score_num"].notna() & (df_show["_score_num"] >= float(min_score))].copy()
        df_unscored = df_show[df_show["_score_num"].isna()].copy()

        if keyword.strip():
            kw = keyword.strip().lower()

            def _hit(r: pd.Series) -> bool:
                fields = [
                    "title", "abstract",
                    "quality_reason", "match_reason", "match_summary",
                ]
                for f in fields:
                    if kw in str(r.get(f, "") or "").lower():
                        return True
                return False

            df_scored = df_scored[df_scored.apply(_hit, axis=1)]
            df_unscored = df_unscored[df_unscored.apply(_hit, axis=1)]

        df_scored = sort_for_browse(df_scored, score_col, sort_mode)
        df_unscored = sort_for_browse(df_unscored, score_col, "æœ€æ–°å‘å¸ƒä¼˜å…ˆ")

        st.markdown("### âœ… å·²è¯„åˆ†ï¼ˆå½“å‰è§†è§’ï¼‰")

        # --- åˆ—åå»é‡ï¼ˆé¿å… pyarrow / streamlit duplicate columns æŠ¥é”™ï¼‰ ---
        def uniq_keep_order(cols):
            seen = set()
            out = []
            for c in cols:
                if c not in seen:
                    out.append(c)
                    seen.add(c)
            return out

        show_cols = [
            score_col,           # å½“å‰è§†è§’åˆ†æ•°ï¼ˆquality_score æˆ– match_scoreï¼‰
            "status",
            "source",
            "title",
            "primary_category",
            "published_at",
            "quality_score",
            "match_score",
            "arxiv_url",
            "pdf_path",
        ]
        show_cols = [c for c in show_cols if c in df_scored.columns]
        show_cols = uniq_keep_order(show_cols)

        # --- åˆ†é¡µæ§ä»¶ ---
        # colP1, colP2, colP3 = st.columns([1, 1, 2])
        # with colP1:
        #     page_size = st.selectbox("å·²è¯„åˆ†ï¼šæ¯é¡µè¡Œæ•°", [20, 50, 100, 200], index=1, key="scored_page_size")
        # total = len(df_scored)
        # max_page = max(1, (total + page_size - 1) // page_size)

        # with colP2:
        #     page = st.number_input("å·²è¯„åˆ†ï¼šé¡µç ", min_value=1, max_value=max_page, value=1, step=1, key="scored_page")

        # with colP3:
        #     st.caption(f"å…± {total} æ¡ï¼Œ{max_page} é¡µ")

        # start = (page - 1) * page_size
        # end = start + page_size

        # st.dataframe(
        #     df_scored.iloc[start:end][show_cols],
        #     use_container_width=True,
        #     height=360,
        # )

        # if total > 0:
        #     st.caption(f"æ˜¾ç¤ºç¬¬ {start + 1} - {min(end, total)} è¡Œ / å…± {total} è¡Œ")

        st.dataframe(df_scored[show_cols], use_container_width=True, height=320)
        
        st.markdown("### ğŸ” è¯¦æƒ…æŸ¥çœ‹")
        uid_pick = st.selectbox("é€‰æ‹© uid", options=df_show["uid"].astype(str).tolist()[:900])
        pick = df_lib[df_lib["uid"].astype(str) == str(uid_pick)]
        if len(pick) > 0:
            r = pick.iloc[0].to_dict()
            st.write(f"**Title**: {r.get('title')}")
            st.write(f"**Status**: {r.get('status')}")
            st.write(f"**Source**: {infer_source(pd.Series(r))}")
            st.write(f"**Published**: {r.get('published_at')}")
            st.write(f"**arXiv**: {r.get('arxiv_url')}")
            st.write(f"**PDF URL**: {r.get('pdf_url')}")
            st.write(f"**Local PDF**: {r.get('pdf_path')}")
            st.markdown("---")
            st.markdown("#### â­ Qualityï¼ˆæ¥è‡ª run_ingest_quality.pyï¼‰")
            st.write(f"**quality_score**: {r.get('quality_score')}")
            st.write(f"**quality_reason**:\n\n{r.get('quality_reason')}")
            st.write(f"**quality_reviewed_at**: {r.get('quality_reviewed_at')}")
            st.markdown("#### ğŸ¯ Matchï¼ˆæ¥è‡ªæœ¬ app çš„ llm_match.pyï¼‰")
            st.write(f"**match_score**: {r.get('match_score')}")
            st.write(f"**match_reason**:\n\n{r.get('match_reason')}")
            st.write(f"**match_summary**:\n\n{r.get('match_summary')}")
            st.write(f"**match_prompt_hash**: {r.get('match_prompt_hash')}")
            st.markdown("#### ğŸ“ Notesï¼ˆabstractï¼Œå¯å†™å¤‡æ³¨ï¼‰")
            st.write(r.get("abstract", ""))


# ----------------------------
# Upload PDFs
# ----------------------------
with tab_upload:
    st.subheader("â¬†ï¸ æ‰¹é‡ä¸Šä¼  PDFï¼ˆå­˜æ¡£ + å¯ç”¨äº Matchï¼‰")
    st.write(f"ä¿å­˜ç›®å½•ï¼š`{pdf_dir}`")
    st.write(f"CSVï¼š`{csv_path}`")

    st.markdown("---")
    st.subheader("ä¸Šä¼ åè‡ªåŠ¨ Qualityï¼ˆå¯é€‰ï¼‰")

    auto_quality = st.checkbox("ä¸Šä¼ å®Œæˆåç«‹å³è·‘ LLM Quality", value=True)
    quality_model = st.text_input("Quality æ¨¡å‹å", value=model)
    quality_sleep = st.slider("Quality æ¯æ¬¡è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰", 0.0, 1.0, 0.0, step=0.1)

    uploaded = st.file_uploader("é€‰æ‹© PDFï¼ˆå¯å¤šé€‰ï¼‰", type=["pdf"], accept_multiple_files=True)

    note = st.text_area(
        "å¯é€‰ï¼šè¿™æ‰¹è®ºæ–‡çš„ç»Ÿä¸€å¤‡æ³¨ï¼ˆå†™å…³é”®è¯ï¼ŒMatch æ›´å‡†ï¼‰",
        value="",
        height=100,
    )

    rename_mode = st.selectbox("æ ‡é¢˜ç­–ç•¥", ["ç”¨æ–‡ä»¶åä½œä¸ºæ ‡é¢˜", "åŠ å‰ç¼€ + æ–‡ä»¶å"], index=0)
    prefix = ""
    if rename_mode.startswith("åŠ å‰ç¼€"):
        prefix = st.text_input("æ ‡é¢˜å‰ç¼€", value="My Paper: ")

    save_btn = st.button("ğŸ’¾ ä¿å­˜åˆ°è®ºæ–‡åº“", type="primary")

    if save_btn:
        if not uploaded:
            st.error("ä½ è¿˜æ²¡é€‰ PDFã€‚")
            st.stop()

        df_now = load_csv(csv_path)
        existing_uids = set(df_now["uid"].astype(str).tolist())

        rows: List[Dict[str, Any]] = []
        saved, skipped = 0, 0

        for f in uploaded:
            data = f.getvalue()
            uid = make_local_uid(data, f.name)

            if uid in existing_uids:
                skipped += 1
                continue

            out_name = safe_filename(uid) + ".pdf"
            out_path = os.path.join(pdf_dir, out_name)
            with open(out_path, "wb") as fp:
                fp.write(data)

            title = f.name
            if rename_mode.startswith("åŠ å‰ç¼€"):
                title = f"{prefix}{f.name}"

            rows.append(local_row_from_upload(uid, title, out_path, note))
            saved += 1

        if rows:
            upsert_rows(csv_path, rows)

        if auto_quality and rows:
            if not use_llm:
                st.warning("ä½ åœ¨ä¾§è¾¹æ å…³é—­äº† GPTï¼Œå› æ­¤è·³è¿‡ Qualityã€‚")
            else:
                with st.status(f"Quality è¯„ä¼°ä¸­...ï¼ˆ{len(rows)} ç¯‡ï¼‰", expanded=True) as status:
                    judgements = batch_quality_llm(
                        rows=rows,  # ç›´æ¥ç”¨åˆšä¸Šä¼ çš„ rowsï¼ˆåŒ…å« uid/title/abstractï¼‰
                        model=quality_model,
                        sleep_s=float(quality_sleep),
                        max_retry=2,
                    )

                    updates = []
                    for j in judgements:
                        updates.append({
                            "uid": j.uid,
                            "quality_score": j.quality_score,
                            "status": j.status,  # accepted / rejected
                            "quality_reason": j.quality_reason,
                            "quality_reviewed_at": now_iso(),
                        })

                    if updates:
                        upsert_rows(csv_path, updates)

                    status.update(label="âœ… Quality å†™å›å®Œæˆ", state="complete")

                st.success("âœ… æœ¬åœ°ä¸Šä¼ è®ºæ–‡å·²å®Œæˆ Quality è¯„åˆ†ä¸ç­›é€‰ã€‚")


        st.success(f"âœ… ä¸Šä¼ å®Œæˆï¼šä¿å­˜ {saved} ç¯‡ï¼Œè·³è¿‡é‡å¤ {skipped} ç¯‡")


# ----------------------------
# Fetch arXiv
# ----------------------------
with tab_arxiv:
    st.subheader("ğŸ›°ï¸ æŠ“å– arXiv æœ€æ–°è®ºæ–‡ï¼ˆåªå†™å…¥ CSVï¼ŒQuality äº¤ç»™è„šæœ¬ï¼‰")

    cats = st.multiselect(
        "arXiv åˆ†ç±»",
        options=["cs.AI", "cs.LG", "cs.CL", "cs.CV", "stat.ML"],
        default=["cs.AI", "cs.LG"],
    )
    fetch_n = st.slider("æŠ“å–æ•°é‡", 10, 500, 150, step=10)
    last_days = st.slider("åªä¿ç•™æœ€è¿‘ N å¤©", 1, 60, 14)

    run_fetch = st.button("ğŸš€ æŠ“å–å¹¶å†™å…¥ CSV", type="primary")

    if run_fetch:
        if not cats:
            st.error("è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†ç±»ã€‚")
            st.stop()

        with st.status("æŠ“å–ä¸­...", expanded=True) as status:
            papers = fetch_arxiv_latest(categories=cats, max_results=fetch_n)
            papers = [p for p in papers if within_last_days(p.published_at, last_days)]
            rows = [paper_to_row_arxiv(p) for p in papers]
            upsert_rows(csv_path, rows)
            status.update(label=f"âœ… å†™å…¥ {len(rows)} ç¯‡åˆ° {csv_path}", state="complete")

        st.success("å®Œæˆï¼æ¥ä¸‹æ¥ä½ è·‘ run_ingest_quality.py åš accepted/rejected å³å¯ã€‚")


# ----------------------------
# Match (llm_match.py)
# ----------------------------
with tab_match:
    st.subheader("ğŸ¯ LLM Matchï¼ˆæŒ‰ Prompt åŒ¹é…ï¼‰")
    st.caption("æœ¬é¡µåªåš Matchï¼šè°ƒç”¨ llm_match.match_one å†™å› match_*ã€‚Quality ä¸åœ¨ app å†…æ‰§è¡Œã€‚")

    df_now = load_csv(csv_path)
    if len(df_now) == 0:
        st.info("åº“ä¸ºç©ºã€‚å…ˆæŠ“ arXiv æˆ–ä¸Šä¼  PDFã€‚")
    else:
        colA, colB, colC, colD, colE = st.columns([1, 1, 1, 1, 1])

        with colA:
            match_scope = st.selectbox("åŒ¹é…èŒƒå›´", ["åªåŒ¹é… accepted", "åŒ¹é…å…¨éƒ¨ï¼ˆä¸ç®¡ statusï¼‰"], index=0)
        with colB:
            max_candidates = st.slider("æœ€å¤šå‚ä¸åŒ¹é…ç¯‡æ•°", 10, 1000, 200, step=10)
        with colC:
            only_new_prompt = st.checkbox("åªå¤„ç†æ²¡è·‘è¿‡è¯¥ prompt çš„è®ºæ–‡ï¼ˆhashä¸åŒï¼‰", value=True)
        with colD:
            min_match_download = st.slider("match_score â‰¥ X æ‰è‡ªåŠ¨ä¸‹è½½ PDFï¼ˆarXivï¼‰", 0, 100, 85)
        with colE:
            per_call_sleep = st.slider("æ¯æ¬¡è°ƒç”¨é—´éš”ï¼ˆç§’ï¼Œé˜²é™é€Ÿï¼‰", 0.0, 1.0, 0.0, step=0.1)

        prompt = st.text_area(
            "ä½ çš„éœ€æ±‚ï¼ˆpromptï¼‰",
            value="æˆ‘æƒ³æ‰¾å…³äº agent + RL å·¥å…·é“¾ï¼ˆè®­ç»ƒ/è¯„ä¼°/éƒ¨ç½²ï¼‰çš„æœ€æ–°å·¥ä½œï¼Œåå·¥ç¨‹è½åœ°ã€å¯å¤ç°ï¼Œæœ€å¥½æœ‰ä»£ç ã€‚",
            height=140,
        )

        run_match = st.button("ğŸš€ è¿è¡Œ Match", type="primary")

        if run_match:
            if not use_llm:
                st.error("ä½ åœ¨ä¾§è¾¹æ å…³é—­äº† GPTã€‚")
                st.stop()

            prompt_hash = compute_prompt_hash(prompt)

            df_scope = df_now.copy()
            df_scope["source"] = df_scope.apply(infer_source, axis=1)

            if match_scope.startswith("åªåŒ¹é… accepted"):
                df_scope = df_scope[df_scope["status"].fillna("").astype(str) == "accepted"]

            if only_new_prompt:
                df_scope = df_scope[
                    df_scope["match_prompt_hash"].isna()
                    | (df_scope["match_prompt_hash"].astype(str).str.strip() != prompt_hash)
                ]

            # ä¼˜å…ˆä»Šå¤©æ–°ã€å†æœ€æ–°å‘å¸ƒ
            df_scope["_published_dt"] = df_scope["published_at"].apply(parse_dt_safe)
            df_scope["is_today"] = df_scope["_published_dt"].apply(lambda x: is_today(x, timezone.utc))
            df_scope = df_scope.sort_values(["is_today", "_published_dt"], ascending=[False, False], na_position="last")
            df_scope = df_scope.head(max_candidates)

            rows_for_match: List[Dict[str, Any]] = []
            for _, r in df_scope.iterrows():
                rows_for_match.append({
                    "uid": str(r.get("uid", "")),
                    "title": str(r.get("title", "")),
                    "abstract": str(r.get("abstract", "")),
                    "authors": str(r.get("authors", "")),
                })

            with st.status(f"LLM Match åŒ¹é…ä¸­...ï¼ˆ{len(rows_for_match)} ç¯‡ï¼‰", expanded=True) as status:
                results = batch_match_llm(
                    prompt=prompt,
                    rows=rows_for_match,
                    model=model,
                    sleep_s=float(per_call_sleep),
                    max_retry=2,
                )

                updates = []
                for rr in results:
                    updates.append({
                        "uid": rr.uid,
                        "match_score": rr.match_score,
                        "match_reason": rr.match_reason,
                        "match_summary": rr.match_summary,
                        "match_prompt_hash": rr.prompt_hash,
                    })

                if updates:
                    upsert_rows(csv_path, updates)

                status.update(label="âœ… Match å†™å›å®Œæˆ", state="complete")

            # è‡ªåŠ¨ä¸‹è½½ï¼šæŒ‰ match_score
            if download_top_k > 0:
                df_after = load_csv(csv_path)
                df_after["source"] = df_after.apply(infer_source, axis=1)
                df_after["match_num"] = pd.to_numeric(df_after.get("match_score"), errors="coerce")

                df_dl = df_after[
                    (df_after["source"] == "arxiv")
                    & (df_after["match_num"].notna())
                    & (df_after["match_num"] >= float(min_match_download))
                ].copy()

                df_dl = df_dl.sort_values("match_num", ascending=False).head(int(download_top_k))

                ok_cnt = 0
                updated_rows = []
                for _, r in df_dl.iterrows():
                    uid = str(r["uid"])
                    pdf_url = str(r.get("pdf_url", "") or "")
                    if not pdf_url.startswith("http"):
                        continue

                    out_path = os.path.join(pdf_dir, f"{safe_filename(uid)}.pdf")
                    if os.path.exists(out_path) and not force_redownload:
                        updated_rows.append({"uid": uid, "pdf_path": out_path})
                        continue

                    ok = download_pdf(pdf_url, out_path)
                    if ok:
                        ok_cnt += 1
                        updated_rows.append({"uid": uid, "pdf_path": out_path})

                if updated_rows:
                    upsert_rows(csv_path, updated_rows)

                st.info(f"ğŸ“¥ è‡ªåŠ¨ä¸‹è½½å®Œæˆï¼š{ok_cnt} ç¯‡ï¼ˆæŒ‰ match_scoreï¼‰")

            st.success("âœ… Match å®Œæˆï¼å»ã€æµè§ˆã€é¡µåˆ‡ Match è§†è§’åˆ·ä½ çœŸæ­£è¦çš„è®ºæ–‡ã€‚")
